---
title: "Module-15"
output: html_document
---
```{r}
library(curl)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(car)
library(knitr)
```
#Multiple Regression - Continuous Response Variable and More than One Continuous Predictor Variables
```{r}
R = matrix(cbind(1, 0.8, -0.5, 0, 0.8, 1, -0.3, 0.3, -0.5, -0.3, 1, 0.6, 0, 
    0.3, 0.6, 1), nrow = 4)
```
```{r}
n <- 1000
k <- 4
M <- NULL
V <- NULL
mu <- c(15, 40, 5, 23)  # vector of variable means
s <- c(5, 20, 4, 15)  # vector of variable SDs
for (i in 1:k) {
    V <- rnorm(n, mu[i], s[i])
    M <- cbind(M, V)
}
M <- matrix(M, nrow = n, ncol = k)
orig <- as.data.frame(M)
names(orig) = c("Y", "X1", "X2", "X3")
head(orig)
```
```{r}
cor(orig)  # variables are uncorrelated
```
```{r}
plot(orig)  # does quick bivariate plots for each pair of variables; using `pairs(orig)` would do the same
```
```{r}
ms <- apply(orig, 2, FUN = "mean")  # returns a vector of means, where we are taking this across dimension 2 of the array 'orig'
ms
```
```{r}
sds <- apply(orig, 2, FUN = "sd")
sds
```
```{r}
normalized <- sweep(orig, 2, STATS = ms, FUN = "-")  # 2nd dimension is columns, removing array of means, function = subtract
normalized <- sweep(normalized, 2, STATS = sds, FUN = "/")  # 2nd dimension is columns, scaling by array of sds, function = divide
head(normalized)  # now a dataframe of Z scores
```
```{r}
M <- as.matrix(normalized)  # redefine M as our matrix of normalized variables
```

```{r}
U = chol(R)
newM = M %*% U
new = as.data.frame(newM)
names(new) = c("Y", "X1", "X2", "X3")
cor(new)  # note that is correlation matrix is what we are aiming for!
```
```{r}
plot(orig)
```
```{r}
plot(new)  # note the axis scales; using `pairs(new)` would plot the same
```
```{r}
df <- sweep(new, 2, STATS = sds, FUN = "*")  # scale back out to original mean...
df <- sweep(df, 2, STATS = ms, FUN = "+")  # and standard deviation
head(df)
```
```{r}
cor(df)
```
```{r}
plot(df)  # note the change to the axis scales; using `pairs(d)` would produce the same plot
```

```{r}
g1 <- ggplot(data = df, aes(x = X1, y = Y)) + geom_point() + geom_smooth(method = "lm", 
    formula = y ~ x)
g2 <- ggplot(data = df, aes(x = X2, y = Y)) + geom_point() + geom_smooth(method = "lm", 
    formula = y ~ x)
g3 <- ggplot(data = df, aes(x = X3, y = Y)) + geom_point() + geom_smooth(method = "lm", 
    formula = y ~ x)
grid.arrange(g1, g2, g3, ncol = 3)
```
```{r}
m1 <- lm(data = df, formula = Y ~ X1)
summary(m1)
```
```{r}
m2 <- lm(data = df, formula = Y ~ X2)
summary(m2)
```

```{r}
m3 <- lm(data = df, formula = Y ~ X3)
summary(m3)
```

```{r}
m <- lm(data = df, formula = Y ~ X1 + X2 + X3)
coef(m)
```
```{r}
summary(m)
```
```{r}
# let's check if our residuals are random normal...
plot(fitted(m), residuals(m))
```
```{r}
hist(residuals(m))
```
```{r}
qqnorm(residuals(m))
```
```{r}
f <- (summary(m)$r.squared * (nrow(df) - (ncol(df) - 1) - 1))/((1 - summary(m)$r.squared) * 
    (ncol(df) - 1))
f
```
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/zombies.csv")
z <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = TRUE)
head(z)
```
```{r}
m <- lm(data = z, height ~ weight + age)
summary(m)
```
#ANCOVA - Continuous Response Variable and Both Continuous and Categorical Predictor Variables
```{r}
m <- lm(data = z, formula = height ~ gender + age)
summary(m)
```
```{r}
m.aov <- Anova(m, type = "II")
m.aov
```
```{r}
plot(fitted(m), residuals(m))
```
```{r}
hist(residuals(m))
```
```{r}
qqnorm(residuals(m))
```
```{r}
p <- ggplot(data = z, aes(x = age, y = height)) + geom_point(aes(color = factor(gender))) + 
    scale_color_manual(values = c("goldenrod", "blue"))
p <- p + geom_abline(slope = m$coefficients[3], intercept = m$coefficients[1], 
    color = "goldenrod4")
p <- p + geom_abline(slope = m$coefficients[3], intercept = m$coefficients[1] + 
    m$coefficients[2], color = "darkblue")
p
```
#Confidence Intervals and Prediction
```{r}
m <- lm(data = z, formula = height ~ age + gender)
summary(m)
```
```{r}
confint(m, level = 0.95)
```
```{r}
ci <- predict(m, newdata = data.frame(age = 29, gender = "Male"), interval = "confidence", 
    level = 0.95)
ci
```
```{r}
pi <- predict(m, newdata = data.frame(age = 29, gender = "Male"), interval = "prediction", 
    level = 0.95)
pi
```
#Interactions Between Predictors
```{r}
m <- lm(data = z, height ~ age + gender + age:gender)  # or
summary(m)
```
```{r}
m <- lm(data = z, height ~ age * gender)
summary(m)
```
```{r}
coefficients(m)
```
```{r}
p1 <- ggplot(data = z, aes(x = age, y = height)) + geom_point(aes(color = factor(gender))) + 
    scale_color_manual(values = c("goldenrod", "blue"))
p1 <- p1 + geom_abline(slope = m$coefficients[2], intercept = m$coefficients[1], 
    color = "goldenrod4")
p1 <- p1 + geom_abline(slope = m$coefficients[2] + m$coefficients[4], intercept = m$coefficients[1] + 
    m$coefficients[3], color = "darkblue")
p1
```
```{r}
p2 <- ggplot(data = z, aes(x = age, y = height)) + geom_point(aes(color = factor(gender))) + 
    scale_color_manual(values = c("goldenrod", "blue")) + geom_smooth(method = "lm", 
    aes(color = factor(gender), fullrange = TRUE))
grid.arrange(p1, p2, ncol = 2)
```
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = TRUE)
head(d)
```
```{r}
d <- select(d, Brain_Size_Female_Mean, Family, Body_mass_female_mean, MeanGroupSize, 
    DayLength_km, HomeRange_km2, Move)
```

```{r}
m <- lm(data = d, log(HomeRange_km2) ~ log(Body_mass_female_mean) + log(Brain_Size_Female_Mean) + 
    MeanGroupSize + Move)
summary(m)
```
```{r}
plot(m$residuals)
```
```{r}
qqnorm(m$residuals)
```
```{r}
shapiro.test(m$residuals)
```
```{r}
m <- lm(data = d, log(HomeRange_km2) ~ log(Body_mass_female_mean) + log(Brain_Size_Female_Mean) + 
    MeanGroupSize)
summary(m)
```
```{r}
plot(m$residuals)
```
```{r}
qqnorm(m$residuals)
```
```{r}
shapiro.test(m$residuals)  # no significant deviation from normal
```